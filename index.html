
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>SHIV</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/solarized-dark.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      
    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Heiarchical Supervisors</h1>
          <p></p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/BerkeleyAutomation">BerkeleyAutomation</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/thomasf/">thomasf</a></span>
        </div>

        <h3>


<center>
<div class="image">
<img src="images/front_image.png" alt="Image cannot be displayed" width="75%">
</div>
</center>

<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Abstract</h3>

<p>For applications such as Amazon warehouse order fulfillment, robots must grasp a desired object amid clutter: other objects that block direct access. This can be difficult to program explicitly due to uncertainty in friction and push mechanics and the variety of objects that can be encountered. Deep Learning networks combined with Online Learning from Demonstration (LfD) algorithms such as DAgger and SHIV have potential to learn robot control policies for such tasks where the input is a camera image and system dynamics and the cost function are unknown.  To explore this idea, we introduce a version of the grasping in clutter problem where a yellow cylinder must be grasped by a planar robot arm amid extruded objects in a variety of shapes and positions. To reduce the burden on human experts to provide demonstrations, we propose using a hierarchy of three levels of supervisors: a fast motion planner that ignores obstacles, crowd-sourced human workers who provide appropriate robot control values remotely via online videos, and a local human expert. Physical experiments suggest that with a fixed budget of 160 expert demonstrations, using the hierarchy of supervisors can increase the probability of a successful grasp (reliability) from $55\%$ to $90\%$.
</p>


  <h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Video for Grasping in Clutter</h3>
<div align="center">
<video width="560" height="315" id="sampleMovie" src="https://github.com/BerkeleyAutomation/shiv/raw/gh-pages/video/LearnedPolicyCASE.mov" controls></video>
</div>

<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>This is an ongoing project at UC Berkeley with active contributions from:<br>
Michael Laskey, <a href="http://www.cs.berkeley.edu/~ftpokorny/">Florian Pokorny</a>, Jeff Mahler, Jonathan Lee, Caleb Chuck, Wesley Hsieh, <a href="http://www.eecs.berkeley.edu/~anca/"> Anca Dragan</a> and <a href="http://goldberg.berkeley.edu">Ken Goldberg</a></p>

<p>Past contributors include:<br>
INSERT PAST CONTRIBUTORS</p>

<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span class="octicon octicon-link"></span></a>Support or Contact</h3>
<p>Please Contact Michael Laskey, <a href="mailto:laskeymd@berkeley.edu">laskeymd@berkeley.edu</a> for code requests or further info</p> 
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
